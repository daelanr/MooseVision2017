#Universal Vision Processor For FRC Team 1391
#Designed for use with Raspberry Pi 3 with OpenCV
import sys
import os
import cv2
import numpy
from enum import Enum
import math
from networktables import NetworkTables
import time
import threading
import copy
import logging
import datetime

############################################################################################
#CHANGE VARIABLES HERE AND ONLY HERE#

#define all hsl values here.
hl = 45
hh = 70
sl = 150
sh = 255
ll = 92
lh = 173

#define roboRIO IP address here
rioIP = '10.13.91.2'

#define all camera IPs and addresses here (as strings). Note: Camera address and IP might be different; in this case using an AXIS M1011, the camera address specifically pulls a mjpeg stream.
camIP = '10.13.91.3'
camAddr = 'http://10.13.91.3/axis-cgi/mjpg/video.cgi?.mjpg'

#define camera attributes (including placement, tech specs, etc.) here
camAngle = 0
camElevation = 0

camXFOV = 47
camYFOV = 35.25
camXRes = 640
camYRes = 480

targetHeight = 10
targetWidth = 15
targetElevation = 85

######################################################################################33
class GripPipeline:
    """
    An OpenCV pipeline generated by GRIP.
    """

    def __init__(self, hl, hh, sl, sh, ll, lh):
        """initializes all values to presets or None if need to be set
        """

        self.__hsl_threshold_hue = [hl, hh]
        self.__hsl_threshold_saturation = [sl, sh]
        self.__hsl_threshold_luminance = [ll, lh]

        self.hsl_threshold_output = None

        self.__find_contours_input = self.hsl_threshold_output
        self.__find_contours_external_only = True

        self.find_contours_output = None

        self.__filter_contours_contours = self.find_contours_output
        self.__filter_contours_min_area = 75.0
        self.__filter_contours_min_perimeter = 0
        self.__filter_contours_min_width = 0
        self.__filter_contours_max_width = 1000.0
        self.__filter_contours_min_height = 0
        self.__filter_contours_max_height = 1000
        self.__filter_contours_solidity = [0.0, 100]
        self.__filter_contours_max_vertices = 1000000
        self.__filter_contours_min_vertices = 0
        self.__filter_contours_min_ratio = 0
        self.__filter_contours_max_ratio = 1000

        self.filter_contours_output = None

        self.good_contours = None
        self.sorted_contours = None

    def process(self, source0):
        """
        Runs the pipeline and sets all outputs to new values.
        """
        # Step HSL_Threshold0:
        self.__hsl_threshold_input = source0
        (self.hsl_threshold_output) = self.__hsl_threshold(self.__hsl_threshold_input, self.__hsl_threshold_hue, self.__hsl_threshold_saturation, self.__hsl_threshold_luminance)

        # Step Find_Contours0:
        self.__find_contours_input = self.hsl_threshold_output
        (self.find_contours_output) = self.__find_contours(self.__find_contours_input, self.__find_contours_external_only)

        # Step Filter_Contours0:
        self.__filter_contours_contours = self.find_contours_output
        self.good_contours = self.__filter_contours(self.__filter_contours_contours, self.__filter_contours_min_area, self.__filter_contours_min_perimeter, self.__filter_contours_min_width, self.__filter_contours_max_width, self.__filter_contours_min_height, self.__filter_contours_max_height, self.__filter_contours_solidity, self.__filter_contours_max_vertices, self.__filter_contours_min_vertices, self.__filter_contours_min_ratio, self.__filter_contours_max_ratio)

        self.sorted_contours = sorted(self.good_contours, key=cv2.contourArea, reverse=True)

        if len(self.sorted_contours) >= 2:
            contour1Atrib = self.contourReport(self.sorted_contours[0])
            contour2Atrib = self.contourReport(self.sorted_contours[1])
            return contour1Atrib, contour2Atrib, (self.hsl_threshold_output)
        else:
            return False, (self.hsl_threshold_output)

    @staticmethod
    def __hsl_threshold(input, hue, sat, lum):
        """Segment an image based on hue, saturation, and luminance ranges.
        Args:
            input: A BGR numpy.ndarray.
            hue: A list of two numbers the are the min and max hue.
            sat: A list of two numbers the are the min and max saturation.
            lum: A list of two numbers the are the min and max luminance.
        Returns:
            A black and white numpy.ndarray.
        """
        #cv2.imshow('opencv input', input)
        #print 'hsl'
        out = cv2.cvtColor(input, cv2.COLOR_BGR2HLS)
        return cv2.inRange(out, (hue[0], lum[0], sat[0]),  (hue[1], lum[1], sat[1]))

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
        Args:
            input: A numpy.ndarray.
            external_only: A boolean. If true only external contours are found.
        Return:
            A list of numpy.ndarray where each one represents a contour.
        """
        #print 'coutouring'
        if(external_only):
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        im2, contours, hierarchy =cv2.findContours(input, mode=mode, method=method)
        #cv2.imshow('hsl', input)
        #print contours
        return contours

    @staticmethod
    def __filter_contours(input_contours, min_area, min_perimeter, min_width, max_width,
                        min_height, max_height, solidity, max_vertex_count, min_vertex_count,
                        min_ratio, max_ratio):
        """Filters out contours that do not meet certain criteria.
        Args:
            input_contours: Contours as a list of numpy.ndarray.
            min_area: The minimum area of a contour that will be kept.
            min_perimeter: The minimum perimeter of a contour that will be kept.
            min_width: Minimum width of a contour.
            max_width: MaxWidth maximum width.
            min_height: Minimum height.
            max_height: Maximimum height.
            solidity: The minimum and maximum solidity of a contour.
            min_vertex_count: Minimum vertex Count of the contours.
            max_vertex_count: Maximum vertex Count.
            min_ratio: Minimum ratio of width to height.
            max_ratio: Maximum ratio of width to height.
        Returns:
            Contours as a list of numpy.ndarray.
        """
        #print 'filtering'
        output = []
        for contour in input_contours:
            #print 'contour?'
            x,y,w,h = cv2.boundingRect(contour)
            if (w < min_width or w > max_width):
                continue
            if (h < min_height or h > max_height):
                continue
            area = cv2.contourArea(contour)
            if (area < min_area):
                continue
            if (cv2.arcLength(contour, True) < min_perimeter):
                continue
            hull = cv2.convexHull(contour)
            solid = 100 * area / cv2.contourArea(hull)
            if (solid < solidity[0] or solid > solidity[1]):
                continue
            if (len(contour) < min_vertex_count or len(contour) > max_vertex_count):
                continue
            ratio = (float)(w) / h
            if (ratio < min_ratio or ratio > max_ratio):
                continue
            #print contour
            output.append(contour)
            #print 'good contour'
        #print output
        return output

def contourReport(contour):
    x, y, w, h = cv2.boundingRect(contour)
    centerx = x + (w/2)
    centery = y + (h/2)
    aspect = float(w)/h
    contourAtrib = {'x':x, 'y':y, 'w':w, 'h':h, 'centerx':centerx, 'centery':centery, 'aspect': aspect}
    return contourAtrib

class Target:

    def __init__(self, width, height, elevation):
        self.width = width
        self.height = height
        self.elevation = elevation

    #returns returns horizontal angle offset between a given point in a frame and the center of the camer lens
    def getAngleX(camera, rectCenterX):
        return camera.xFOV*(float(rectCenterX - camera.halfXRes)/camera.halfXRes)

    #returns vertical angle offset between a given point in a frame and the center of the camer lens
    def getAngleY(Camera, rectCenterY):
        return camera.yFOV*(float(rectCenterY - camera.halfYRes)/camera.halfYRes)

    #returns distance to target based on target height
    def getDistHeight(self, camera, rectHeight):
        return float(self.height*camera.yRes)/(2*rectHeight*(math.tan(math.radians(camera.halfYFOV))))

    #Returns distance to target based on target width
    def getDistWidth(self, camera, rectWidth):
        return float(self.width*camera.xRes)/(2*rectWidth*(math.tan(math.radians(camera.halfXFOV))))

    #returns distance to target
    def getDistElevation(self, camera, rectLowerY):
        return float(self.elevation)/math.tan(math.radians(self.getAngleY(rectLowerY)-camera.angle))

class NetworkDevice:

    def __init__(self, ip):
        self.ip = ip
        self.isConnected = False

    #determines whether connection to a network device (roboRIO, camera) is possible
    def ping(self):
        if os.system("ping " + str(self.ip) + " -c 1 -W 3") == 0:
            self.isConnected = True
            return True
        else:
            self.isConnected = False
            return False

    #returns result of last ping
    def getConnectionStatus(self):
        return self.isConnected

class Camera(NetworkDevice):

    #returns camera object with given perameters
    def __init__(self, ip, addr, angle, elevation, xRes, yRes, xFOV, yFOV):
        self.xFOV = xFOV
        self.yFOV = yFOV
        self.xRes = xRes
        self.yRes = yRes
        self.halfXFOV = float(xFOV) / 2
        self.halfYFOV = float(yFOV) / 2
        self.halfXRes = xRes / 2
        self.halfYRes = yRes / 2
        self.ip = ip
        self.addr = addr
        self.angle = angle
        self.elevation = elevation
        self.cv2CameraObject = False

    #Passed camera object, attempts to connect x times
    def connect(self, tries):
        global logger

        for i in range(tries):
            logger.info('Connecting to camera...')
            try:
                self.cv2CameraObject = cv2.VideoCapture(self.addr)
            except:
                logger.warning('Camera inaccessible! %s tries left.', str(range(tries)-i))
                continue

            camTestBool, val = self.cv2CameraObject.read()

            if camTestBool:
                self.isConnected = True
                logger.info('Camera connected.')
                break
            else:
                logger.warning('Camera inaccessible! %s tries left.', str(range(tries)-i))
                self.isConnected = False
                self.cv2CameraObject = False

    #Attempts to return a frame from given object
    def getFrame(self):
        global logger

        logger.debug('Retrieving frame from camera...')
        try:
            retVal, img = self.cv2CameraObject.read()
        except:
            logger.warning('Frame unavailable!')
            self.isConnected = False
            return False
        if retVal:
            logger.debug('Frame retrieved.')
            return img
        else:
            logger.warning('Frame unavailable!')
            self.isConnected = False
            return False

class roboRIO(NetworkDevice):
    def __init__(self, ip):
        self.ip = ip
        self.sd = None

    #initializes connection with SmartDashboard
    def networkTableInit():
        global logger

        logger.info('Initializing networktables...')
        try:
            NetworkTables.initialize(server=str(ip))
            NetworkTables.setWriteFlushPeriod(30)
            self.sd = NetworkTables.getTable('SmartDashboard')
            self.isConnected = True
            logger.info('Networktables initialized.')
        except:
            logger.critical('UNABLE TO INITIALIZE NETWORKTABLES')
            self.isConnected = False

    #returns the value of item with a given key from the SmartDashboard
    def getValue(self, type_, name):
        global logger

        try:
            logger.debug('Retriveing %s (%s) from networktables.', name, type_)
            exec("value = self.sd.get"+type_+"(\'"+name+"\')")
            self.isConnected = True
            return value
        except:
            logger.warning('Unable to retrieve %s (%s) from networktables!', name, type_)
            self.isConnected = False

    #puts item with given value and given key from the SmartDashboard
    def putValue(self, type_, name, value):
        global logger
        try:
            logger.debug('Publishing %s (%s) to networktables.', name, type_)
            exec('self.sd.put'+type_+'(\''+name+'\', \''+value+'\')')
            self.isConnected = True
        except:
            logger.warning('Unable to publish %s (%s) to networktables!', name, type_)
            self.isConnected = False

#used to communicate between program threads intead of variables.
#any variables that need to be accessed by both manageCameras() and manageComputation() should instead be instances of MultiThreadVariable; this object and its associated read() and write() functions have implemented memory protection
class MultiThreadVariable:
    global logger

    def __init__(self, value):
        self.value = value
        self.Lock = threading.Lock()

    def write(self, value):
        logger.debug('Writing to MTV')
        with self.Lock:
            self.value = copy.copy(value)

    def read(self):
        logger.debug('Reading from MTV')
        with self.Lock:
            return self.value

def initialize():
    #use this method to connect to networktables, instantiate and connect to cameras, create an instance of the pipe process, set debugging and logging perameters, etc; every function that runs once at program bootup should be defined here.
    global isShowFrames
    global isDebugging
    global isNetworked
    global isWarning
    global roboRIO
    global logger

    isShowFrames = False
    isDebugging = False
    isNetworked = True
    isWarning = False

    if len(sys.argv) > 1:
        for arg in sys.argv:
            if arg == "-s":
                isShowFrames = True
            if arg == "-d":
                isDebugging = True
            if arg == '-n':
                isNetworked = False
            if arg == '-w':
                isWarning = True
    FORMAT = logging.Formatter(fmt='%(levelname)s : %(threadName)s @ %(asctime)s : %(message)s')
    FILE_HANDLER = logging.FileHandler('visionlogs/'+(str(datetime.datetime.now().strftime('%m-%d-%y@%H:%M:%S'))+'.log'))
    FILE_HANDLER.setFormatter(FORMAT)
    STREAM_HANDLER = logging.StreamHandler(stream=sys.stdout)
    STREAM_HANDLER.setFormatter(FORMAT)
    logger = logging.getLogger()
    logger.addHandler(FILE_HANDLER)
    logger.setLevel(logging.INFO)
    if isDebugging:
        logger.addHandler(STREAM_HANDLER)
        logger.setLevel(logging.DEBUG)
    if isWarning:
        logger.setLevel(logging.WARNING)
    logger.info('Debugging perameters set. Logging system initialized.')
    target = Target(targetWidth, targetHeight, targetElevation)

    if isNetworked:
        roboRIO = roboRIO(rioIP)
        logger.info('Pinging roboRIO...')
        while roboRIO.ping() == False:
            logger.warning('RoboRIO inaccessible! Retrying...')
            time.sleep(1)
        logger.info('RoboRIO connected.')
        roboRIO.networkTableInit()
        logger.info('Network Tables Initailized.')
    camera = Camera(camIP, camAddr, camAngle, camElevation, camXRes, camYRes, camXFOV, camYFOV)
    logger.info('Pinging camera...')
    while camera.ping() == False:
        time.wait(1)
        logger.warning('Camera inaccessible!')
    camera.connect(5)

    pipe = GripPipeline()

    sharedImageTuple = MultiThreadVariable((False, False))

    #As a final step in this method, create the two program threads and initialize both.

    logger.info('Initializing camera and computation threads.')
    cameraThread = Thread.threading(target=manageCamera, args=(camera, sharedImageTuple), name='Camera Manager')
    computeThread = Thread.threading(target=manageComputation, args=(pipe, target, roboRIO, sharedImageTuple), name='Processing Manager')
    cameraThread.start()
    computeThread.start()

def manageCamera(camera, sharedImageTuple):
    global logger
    #this loop will run continuously at the end of the initialize() sequence.
    #It should contain all code pertaining to pulling frames from a camera. It should also include all code that tries to reconnect to disconnected cameras, and pass the pulled frame as a MultiThreadVariable to the computationThread
    logger.info('Camera Thread initialized.')
    while True:
        img = camera.getFrame()
        if img == False:
            logger.warning()
            camera.connect(1)
        else:
            sharedImageTuple.write((img, True))


def manageComputation(pipe, target, roboRIO, sharedImageTuple):
    #this loop will run continuously at the end of the initialize() sequence.
    #It should contain all code that must be run to process each frame.
    global isShowFrames
    global isDebugging

    if isShowFrames:
        cv2.namedWindow("image")
        cv2.namedWindow('hsl')
    logger.info('Computation Thread initialized.')
    while True:
        img, isNewFrame = sharedImageTuple.read()
        sharedImageTuple.read(None, False)
        if isNewFrame == False:
            logger.debug('No new frame.')
            continue
        logger.info('Processing frame...')
        logger.debug('Finding contours...')
        outputs, hsl = pipe.process(img)
        contours = sorted(outputs, key=cv2.contourArea, reverse=True)
        logger.debug('Contours processed')

        if len(contours) >= 1:
            logger.debug('Processing contours...')
            contourAtrib = contourReport(contours[0])
            angle = target.getXAngle(contourAtrib[centerx])
            dist = target.getDistHeight(contourAtrib[h])
            isTargetInFrame = True
            logger.debug('Contours processed.')
            logger.info('Frame processed.')
            if isShowFrames:
                cv2.rectangle(img, (320, 240), (320, 240), (255, 0, 0), 5)
                cv2.rectangle(img, (contourAtrib[x],contourAtrib[y]), (contourAtrib[x]+contourAtrib[w], contourAtrib[y]+contourAtrib[h]), (255,0,0), 1)
                cv2.rectangle(img, (contourAtrib[centerx], contourAtrib[centery]), (contourAtrib[centerx], contourAtrib[centery]), (0,0,255), 1)
        else:
            logger.info('Not enough contours; no target in frame.')
            angle = 0
            dist = 0
            targetInFrame = False
        if isNetworked:
            logger.info('Publishing values to network tables.')
            roboRIO.putValue('Number', 'angle', angle)
            roboRIO.putValue('Number', 'dist', dist)
            roboRIO.putValue('Boolean', 'isTargetInFrame', isTargetInFrame)
            logger.info('Values published.')
        else:
            print 'Angle: '+str(angle)
            print 'Dist: '+str(dist)
            print 'isTargetInFrame'+str(isTargetInFrame)
        if isShowFrames:
            cv2.imshow('image', img)
            cv2.imshow('hsl', hsl)

initialize()
